{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Tweets from Streaming Socket\n",
    "\n",
    "Group Project for Big Data Programming, Fall 2017\n",
    "\n",
    "### Project Contributors:\n",
    "Caleb Hulburt   \n",
    "Mohammad Azim   \n",
    "Yao Jin   \n",
    "Xian Lai   \n",
    "\n",
    "========================================================\n",
    "\n",
    "![](../images/logos.png)\n",
    "\n",
    "This application focuses on analysing streaming tweets in a distributed manner under the framework of Spark. Spark provides a streaming processing API call SparkStreaming in mini-batch. It chops a continuous stream into discrete chunks with given time interval. Each chunk is saved as an RDD. Then operations are applied on this discrete RDD stream called DStream.\n",
    "\n",
    "#### Tweepy:\n",
    "Firstly we use tweepy API to pull tweets streams regard tracks #MAGA and #resist. Then the stream is directed into Spark Streaming through the TCP socket.\n",
    "\n",
    "#### Spark:\n",
    "Inside Spark, raw tweets are cleaned into words and then analyzed by following steps:\n",
    "1. We calculate the term frequency of each word, sort them by frequency and take the top 5000 under each label.\n",
    "2. We use these 10,000 words as our features and encode the MAGA tweets and resist tweets into structured datasets. Each feature value is either True or False meaning whether this feature has appears in this tweet.\n",
    "3. We calculate the conditional probabilities of each feature given label.\n",
    "4. At last we calculate the \"informativeness\" of features based on previous conditional probabilities.\n",
    "\n",
    "The benefits using Spark for streaming process:\n",
    "1. The computation are distributed across machines so it is scalable, thus we can control the latency no matter stream is small or big.\n",
    "2. The streaming analysis is based on RDD's. As stated in overview, RDD is stored in memory so it's good for interactively analysis or repetitive analysis like machine learning.\n",
    "3. Spark Streaming is also a very high level API so you don't need to worry about low level details.\n",
    "\n",
    "#### Bokeh:\n",
    "Then we collect the analysis result and visualize the top 100 feature word with the highest informativeness interactively using Bokeh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"a901d5c6-71f9-4a37-9f0f-593261d48a77\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io import _state; print(_state.uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"from bokeh import io; io._destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(`.${CLASS_NAME.split(' ')[0]}`);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"a901d5c6-71f9-4a37-9f0f-593261d48a77\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"a901d5c6-71f9-4a37-9f0f-593261d48a77\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'a901d5c6-71f9-4a37-9f0f-593261d48a77' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.9.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.9.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.9.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.9.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.9.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.9.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.9.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.9.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.9.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.9.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"a901d5c6-71f9-4a37-9f0f-593261d48a77\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"a901d5c6-71f9-4a37-9f0f-593261d48a77\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"a901d5c6-71f9-4a37-9f0f-593261d48a77\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'a901d5c6-71f9-4a37-9f0f-593261d48a77' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.9.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.9.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.9.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.9.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.9.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.9.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.9.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.9.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.9.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.9.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"a901d5c6-71f9-4a37-9f0f-593261d48a77\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from time import strftime, gmtime, sleep\n",
    "import TweetsStreamingPlot as tsp\n",
    "from math import log\n",
    "import subprocess\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To receive tweets in Spark, we first run the tweets listener python file as a background sub-process. It will pull the tweets and send them to port 5555 at IPAddress '172.17.0.2' which is the address of this docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_    = subprocess.Popen(['python', 'TweetsListener.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to filter stop words in tweets, we prepared the vocabulary as a list.\n",
    "with open(\"../data/stop_words.txt\", 'r') as f: STOPWORDS = f.read()\n",
    "    \n",
    "STOPWORDS = STOPWORDS.split(\"\\n\")\n",
    "STOPWORDS = [word for word in STOPWORDS if word != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'color':[], 'size':[], 'x':[], 'y':[], 'text':[]}  # the data source for plotting\n",
    "plot = tsp.StreamingPlot(width=900, height=900)            # the streaming plotting object\n",
    "logs = open('batch_log.txt', 'w')                          # the file saving intermediate and final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeHeader():\n",
    "    \"\"\"print time header\"\"\"\n",
    "    return (\"\\n----------------------------\") + \\\n",
    "           (\"Time: \" + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())) + \\\n",
    "           (\"----------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the Spark context in local mode with 3 CPU's running simulating 3 different machines. And build a Spark streaming context based on Spark context and set the time interval to 5 seconds. So the incoming tweets will be collect into 1 RDD every 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster('local[3]')\n",
    "sc   = SparkContext(conf=conf)\n",
    "ssc  = StreamingContext(sc, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets cleaning:\n",
    "\n",
    "We receive tweets sending from tweets listener script through assigned port. Because the raw tweets are strings full of emojis and wired symbols. We preprocess them by spliting each line into words, removing useless symbols, tranforming all words into lower cases, removing stop words and assign one of the labels to each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(words):\n",
    "    \"\"\" Assign labels to tweets. If this tweet has word resist in it, \n",
    "    then we assign label resist to it. Else if it has word maga, we \n",
    "    label it as maga. If it doesn't have either words, we return none.\n",
    "    In the same time we remove the label word from the words.\n",
    "    \n",
    "    Inputs: words: one tweet in form of a list of cleaned words.\n",
    "    Output: labeled tweet: (label, words)\n",
    "    \"\"\"\n",
    "    if 'resist' in words:\n",
    "        words = [x for x in words if x != 'resist']\n",
    "        return('resist', words)\n",
    "    if 'maga' in words:\n",
    "        words = [x for x in words if x != 'maga']\n",
    "        return('maga', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeRDD(rdd):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    global logs\n",
    "    logs.write(timeHeader())\n",
    "    logs.write(\"\\nRaw Tweets:\\n{}\".format(rdd.take(num=1)))\n",
    "    logs.flush()\n",
    "    \n",
    "raw_tweets = ssc.socketTextStream('172.17.0.2',5555)\n",
    "raw_tweets.foreachRDD(writeRDD)\n",
    "# raw_tweets.pprint()\n",
    "\n",
    "# for each rdd in stream:\n",
    "# split the string by space\n",
    "# remove char that is not a letter or number\n",
    "# lower case all the words\n",
    "# remove empty strings\n",
    "# remove stop words\n",
    "# remove empty list\n",
    "# assign label to each tweets\n",
    "# remove tweets that don't belong to any label\n",
    "clean_tweets = raw_tweets\\\n",
    "    .map(lambda x: x.split())\\\n",
    "    .map(lambda x: [re.sub(r'([^\\s\\w]|_)+', '', y) for y in x])\\\n",
    "    .map(lambda x: [word.lower() for word in x])\\\n",
    "    .map(lambda x: [word for word in x if word != ''])\\\n",
    "    .map(lambda x: [word for word in x if word not in STOPWORDS])\\\n",
    "    .filter(lambda x: x != [])\\\n",
    "    .map(assign_label)\\\n",
    "    .filter(lambda x: x != None)    \n",
    "# clean_tweets.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis:\n",
    "\n",
    "After cleaning, the tweets are a stream of RDD's. Each RDD contains tweets for last 5 seconds, each tweet is stored in a row as a tuple (label, words). We further use window method in Spark Streaming to take all the tweets from last 60 seconds and perform analysis on them. \n",
    "\n",
    "![](../images/DStreams.png)\n",
    "\n",
    "### Functions for analysis:\n",
    "The informativeness of features defined by the biggest ratio of conditional probability:\n",
    "\n",
    "$$maxarg\\left( \\frac{p(feature|label=resist)}{p(feature|label=maga)}, \\frac{p(feature|label=maga)}{p(feature|label=resist)}\\right)$$\n",
    "\n",
    "Intuitively, it means how much information can this feature word tells you for classifying this tweet as maga or resist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_by_label(rdd):\n",
    "    \"\"\" count the number of tweets by label\n",
    "    \"\"\"\n",
    "    global logs\n",
    "    \n",
    "    # count the number of maga tweets\n",
    "    # count the number of resist tweets\n",
    "    # flatten the words so that each row is (label, word)\n",
    "    n_maga   = float(rdd.filter(lambda x: x[0] == 'maga').count())\n",
    "    n_resist = float(rdd.filter(lambda x: x[0] == 'resist').count())\n",
    "    new_rdd  = rdd.flatMapValues(lambda x: x)\n",
    "    \n",
    "    logs.write('\\n# Resist Tweets: {}\\t # MAGA Tweets: {}'\\\n",
    "        .format(int(n_resist), int(n_maga)))\n",
    "    logs.flush()\n",
    "    \n",
    "    return new_rdd, n_resist, n_maga\n",
    "\n",
    "\n",
    "def fetch_features(rdd):\n",
    "    \"\"\" fetch top 5000 features for each label\n",
    "    \"\"\"\n",
    "    global logs\n",
    "    \n",
    "    # input rdd has rows: (label, word)\n",
    "    # use the label and word as key as add count 1: ((label, word), 1)\n",
    "    # add up the count: ((label, word), count)\n",
    "    # reorganize: (label, (word, count))\n",
    "    new_rdd = rdd.map(lambda x: (x, 1))\\\n",
    "        .reduceByKey(lambda a, b: a+b)\\\n",
    "        .map(lambda x: (x[0][0], (x[0][1], x[1])))\\\n",
    "    #    .sortBy(lambda x: x[1][1], ascending=False)\n",
    "        \n",
    "    # maga features are top 5000 words with highest count\n",
    "    m_feats = new_rdd.filter(lambda x: x[0] == 'maga')\\\n",
    "        .takeOrdered(5000, key = lambda x: -x[1][1])\n",
    "    # resist features are top 5000 words with highest count\n",
    "    r_feats = new_rdd.filter(lambda x: x[0] == 'resist')\\\n",
    "        .takeOrdered(5000, key = lambda x: -x[1][1])\n",
    "    \n",
    "    logs.write(\"\\nMAGA features:\\n{}\".format(m_feats[:10]))\n",
    "    logs.write(\"\\nresist features:\\n{}\".format(r_feats[:10]))\n",
    "    logs.flush()\n",
    "    \n",
    "    return m_feats, r_feats\n",
    "\n",
    "\n",
    "def collect_feature_counts(maga_feats, resist_feats):\n",
    "    \"\"\" collect the words for each label as a list.\n",
    "    collect the word:count for each label as a dictionary.\n",
    "    \"\"\"\n",
    "    words, counts = {}, {}\n",
    "    # create a dictionary: label:feature_words\n",
    "    words['m'] = [x[1][0] for x in maga_feats]\n",
    "    words['r'] = [x[1][0] for x in resist_feats]\n",
    "    \n",
    "    # create a dictionary: label:feature_word_counts\n",
    "    # feature_word_counts is a dictionary of word:count pairs\n",
    "    counts['m'] = {x[1][0]:x[1][1] for x in maga_feats}\n",
    "    counts['r'] = {x[1][0]:x[1][1] for x in resist_feats}\n",
    "    \n",
    "    return words, counts\n",
    "\n",
    "\n",
    "def combine_feature_counts(counts):\n",
    "    \"\"\" create a combined dictionary with pairs {word:[count_maga, \n",
    "    count_resist]}, for word only appears in one dataset, we will \n",
    "    assign 1 as count to avoid zero divide\"\"\"\n",
    "    global logs\n",
    "    combined_counts = {}\n",
    "    \n",
    "    # if a word appears in only maga tweets, we add word:[count_maga, 1]\n",
    "    # if a word appears in both tweets, we add word:[count_maga, count_resist]\n",
    "    # if a word appears in only resist tweets, we add word:[1, count_resist]\n",
    "    for word, count in counts['m'].items():\n",
    "        if count <= 1: continue\n",
    "        if word not in counts['r'].keys():\n",
    "            combined_counts[word] = [count, 1]\n",
    "        else:\n",
    "            combined_counts[word] = [count, counts['r'][word]]\n",
    "    for word, count in counts['r'].items():\n",
    "        if count <= 1: continue\n",
    "        if word not in combined_counts.keys():\n",
    "            combined_counts[word] = [1, count]\n",
    "            \n",
    "    logs.write(\"\\nCombined feature_counts_by_label: {}\".format(list(combined_counts.items())[:10]))\n",
    "    logs.flush()\n",
    "\n",
    "    return combined_counts\n",
    "\n",
    "\n",
    "def calculate_informativeness(cps):\n",
    "    \"\"\" takes in the conditional probablities of one feature and \n",
    "    calculate the informativeness of this feature.\n",
    "    \n",
    "    inputs:\n",
    "    -------\n",
    "    cps[0]: the conditional probability of this feature word given label maga\n",
    "    cps[1]: the conditional probability of this feature word given label resist\n",
    "    \"\"\"\n",
    "    return round(max(cps[0]/cps[1], cps[1]/cps[0]), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for preparing plotting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(list_):\n",
    "    \"\"\"normalize a list to range [0, 1]\"\"\"\n",
    "    max_, min_ = max(list_), min(list_)\n",
    "    return [(x - min_)/(max_ - min_) for x in list_]\n",
    "\n",
    "\n",
    "def plot_data(infs, words):\n",
    "    \"\"\" transform the informativeness to plotting data source.\n",
    "    We will use the labels as scatter circles' color, informativeness \n",
    "    as scatter circles' sizes, words as texts, cp_maga as x, cp_resist \n",
    "    as y.\n",
    "    \n",
    "    Inputs:\n",
    "    -------\n",
    "    - infs: a list of tuples, each tuple is in form: \n",
    "        (feature_word, cp_maga, cp_resist, informativness)\n",
    "    - words: the list of feature words for each label.\n",
    "    \"\"\"\n",
    "    global data, logs\n",
    "    \n",
    "    text, other = zip(*infs)\n",
    "    x, y, size  = zip(*other)\n",
    "    data['x']   = min_max_scale(x)\n",
    "    data['y']   = min_max_scale(y)\n",
    "    \n",
    "    color = [1 - x_ + y_ for x_, y_ in zip(data['x'], data['y'])]\n",
    "    color = min_max_scale(color)\n",
    "    color = [tsp.cms['RdBu'][int(c/0.1)] for c in color]\n",
    "    data['color'] = color\n",
    "    \n",
    "    size = min_max_scale(size)\n",
    "    data['size']  = [x/20 for x in size]\n",
    "    data['text']  = text\n",
    "    \n",
    "    logs.write('\\nFeature\\tCond_prop_1\\tCond_prob_2\\tInformativeness')\n",
    "    for f, x_, y_, i in zip(text[:10], x[:10], y[:10], size[:10]):\n",
    "        logs.write('\\n{}\\t{:.3f}\\t{:.3f}\\t{:.3f}'.format(f, x_, y_, i))\n",
    "    logs.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(rdd):\n",
    "    \"\"\" Take in the RDD with cleaned tweets and perform analysis. Save the results \n",
    "    to logs text file as well as interactive plots.\n",
    "    \"\"\"\n",
    "    # count the number of tweets\n",
    "    new_rdd, n_resist, n_maga = count_by_label(rdd)\n",
    "    maga_feats, resist_feats = fetch_features(new_rdd)\n",
    "    words, counts = collect_feature_counts(maga_feats, resist_feats)\n",
    "    combined_counts = combine_feature_counts(counts)\n",
    "\n",
    "    # we parallelize the combined_counts onto the cluster, \n",
    "    # each row in form: (word, (count_maga, count_resist))\n",
    "    # calculate the conditional probabilities for each label\n",
    "    # take the log for conditional probabilities and calculate informativeness using conditional probs\n",
    "    # sort the rows by informativeness and take the top 5000 rows.\n",
    "    infs = sc.parallelize(combined_counts.items())\\\n",
    "        .mapValues(lambda x: (x[0]/n_maga, x[1]/n_resist))\\\n",
    "        .mapValues(lambda x: (log(x[0]), log(x[1]), calculate_informativeness(x)))\\\n",
    "        .sortBy(lambda x: x[1][2], ascending=False)\\\n",
    "        .take(5000)\n",
    "\n",
    "    plot_data(infs[:100], words)\n",
    "\n",
    "\n",
    "clean_tweets.window(60).foreachRDD(analysis)\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"2f1119ed-dedc-4cac-9c93-77a831002589\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"590bfea0-4bf0-4a1f-95d7-41b8011b90f9\":{\"roots\":{\"references\":[{\"attributes\":{\"axis_label\":\"p(word|label='maga')\",\"formatter\":{\"id\":\"82742bf6-83ed-40a4-adfc-e83428a8314d\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"0aca651c-7e06-486a-a56a-85397408c832\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"cf2d7c46-8786-4b4a-8fbb-24d5d3778ba3\",\"type\":\"BasicTicker\"}},\"id\":\"97259b57-418f-4df3-8a28-22a213bd7a50\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\",\"text\",\"color\",\"size\"],\"data\":{\"color\":[],\"size\":[],\"text\":[],\"x\":[],\"y\":[]}},\"id\":\"742eef2c-13e8-4984-ac86-56c44fad4f49\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.5},\"line_color\":{\"value\":\"#1f77b4\"},\"radius\":{\"field\":\"size\",\"units\":\"data\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"217064d6-6d34-4f04-932c-dd1f15576dcb\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"cf2d7c46-8786-4b4a-8fbb-24d5d3778ba3\",\"type\":\"BasicTicker\"},{\"attributes\":{\"dimension\":1,\"grid_line_color\":{\"value\":null},\"grid_line_dash\":[2,4],\"minor_grid_line_color\":{\"value\":\"#aaaaaa\"},\"minor_grid_line_dash\":[2,4],\"plot\":{\"id\":\"0aca651c-7e06-486a-a56a-85397408c832\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"cf2d7c46-8786-4b4a-8fbb-24d5d3778ba3\",\"type\":\"BasicTicker\"}},\"id\":\"3948f359-29c2-484e-9b93-fa7ea141e1d6\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"73720a4f-f145-46ca-93b9-8e0cffc6971d\",\"type\":\"PanTool\"},{\"attributes\":{\"border_line_color\":{\"value\":\"white\"},\"level\":\"glyph\",\"plot\":{\"id\":\"0aca651c-7e06-486a-a56a-85397408c832\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"source\":{\"id\":\"742eef2c-13e8-4984-ac86-56c44fad4f49\",\"type\":\"ColumnDataSource\"},\"text_color\":{\"field\":\"color\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"f320e283-eb68-4d07-9885-807cee83e106\",\"type\":\"LabelSet\"},{\"attributes\":{\"data_source\":{\"id\":\"fc10e6c2-0651-4b47-b3f6-7c6400415802\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"70ec24a7-8019-4f15-9f5f-0db021593d62\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"89cc58eb-3ab8-45ae-b2a3-cc36f98eedab\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"f9f23467-c79d-4eae-ae3d-fb51302c50dd\",\"type\":\"CDSView\"}},\"id\":\"5eccf63e-4224-478e-b7a5-2cfb9c10a33a\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"background_fill_color\":{\"value\":\"#282828\"},\"below\":[{\"id\":\"de4616a2-6f36-42ec-b67f-d0fc519b5258\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"97259b57-418f-4df3-8a28-22a213bd7a50\",\"type\":\"LinearAxis\"}],\"plot_height\":900,\"plot_width\":900,\"renderers\":[{\"id\":\"de4616a2-6f36-42ec-b67f-d0fc519b5258\",\"type\":\"LinearAxis\"},{\"id\":\"a3b7876c-08e5-471b-a304-55fa90448162\",\"type\":\"Grid\"},{\"id\":\"97259b57-418f-4df3-8a28-22a213bd7a50\",\"type\":\"LinearAxis\"},{\"id\":\"3948f359-29c2-484e-9b93-fa7ea141e1d6\",\"type\":\"Grid\"},{\"id\":\"f320e283-eb68-4d07-9885-807cee83e106\",\"type\":\"LabelSet\"},{\"id\":\"5eccf63e-4224-478e-b7a5-2cfb9c10a33a\",\"type\":\"GlyphRenderer\"},{\"id\":\"404513db-de0f-4ed0-816d-baafeb98d22d\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"f2692e59-f91f-44c1-ab2b-ddb6defc459d\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"9bd03db6-592a-4823-b02c-0f076fd9ccb0\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"e5c32003-c19c-4cbc-9b92-48a2bc225859\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"a15b589c-081e-40ac-adbd-318638b69d56\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"9f9ce086-bcee-4551-b213-b08ea2e42495\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"32bb2eb6-7c92-4655-9c33-1137b3eab513\",\"type\":\"LinearScale\"}},\"id\":\"0aca651c-7e06-486a-a56a-85397408c832\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"plot\":null,\"text\":\"Streaming text analysis\"},\"id\":\"f2692e59-f91f-44c1-ab2b-ddb6defc459d\",\"type\":\"Title\"},{\"attributes\":{\"source\":{\"id\":\"fc10e6c2-0651-4b47-b3f6-7c6400415802\",\"type\":\"ColumnDataSource\"}},\"id\":\"f9f23467-c79d-4eae-ae3d-fb51302c50dd\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"4f5226a0-d33e-4a21-bfd6-993260a2829b\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null},\"id\":\"e5c32003-c19c-4cbc-9b92-48a2bc225859\",\"type\":\"DataRange1d\"},{\"attributes\":{\"line_color\":{\"value\":\"#1f77b4\"},\"line_dash\":[6],\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"70ec24a7-8019-4f15-9f5f-0db021593d62\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"6fc95636-31a3-472a-9eb7-0ed522cb6e25\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"efc631c9-9de7-4df7-9627-800e6cdf9ea4\",\"type\":\"ResetTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"73720a4f-f145-46ca-93b9-8e0cffc6971d\",\"type\":\"PanTool\"},{\"id\":\"6fc95636-31a3-472a-9eb7-0ed522cb6e25\",\"type\":\"WheelZoomTool\"},{\"id\":\"efc631c9-9de7-4df7-9627-800e6cdf9ea4\",\"type\":\"ResetTool\"},{\"id\":\"eb501f15-99aa-4d4c-b844-af84225cab21\",\"type\":\"SaveTool\"}]},\"id\":\"9bd03db6-592a-4823-b02c-0f076fd9ccb0\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"eb501f15-99aa-4d4c-b844-af84225cab21\",\"type\":\"SaveTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":[0,1],\"y\":[0,1]}},\"id\":\"fc10e6c2-0651-4b47-b3f6-7c6400415802\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"a15b589c-081e-40ac-adbd-318638b69d56\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"82742bf6-83ed-40a4-adfc-e83428a8314d\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null},\"id\":\"9f9ce086-bcee-4551-b213-b08ea2e42495\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"32bb2eb6-7c92-4655-9c33-1137b3eab513\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"742eef2c-13e8-4984-ac86-56c44fad4f49\",\"type\":\"ColumnDataSource\"}},\"id\":\"9bbd6873-73fd-4ed7-871f-3e1f154d89c2\",\"type\":\"CDSView\"},{\"attributes\":{\"axis_label\":\"p(word|label='resist')\",\"formatter\":{\"id\":\"4f5226a0-d33e-4a21-bfd6-993260a2829b\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"0aca651c-7e06-486a-a56a-85397408c832\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"71bd440f-aa59-46f7-8f9f-dfaa8dc0e084\",\"type\":\"BasicTicker\"}},\"id\":\"de4616a2-6f36-42ec-b67f-d0fc519b5258\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"radius\":{\"field\":\"size\",\"units\":\"data\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"bf874ea0-a75a-460c-81c8-30063aac60dc\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"71bd440f-aa59-46f7-8f9f-dfaa8dc0e084\",\"type\":\"BasicTicker\"},{\"attributes\":{\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"line_dash\":[6],\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"89cc58eb-3ab8-45ae-b2a3-cc36f98eedab\",\"type\":\"Line\"},{\"attributes\":{\"data_source\":{\"id\":\"742eef2c-13e8-4984-ac86-56c44fad4f49\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"217064d6-6d34-4f04-932c-dd1f15576dcb\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"bf874ea0-a75a-460c-81c8-30063aac60dc\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"9bbd6873-73fd-4ed7-871f-3e1f154d89c2\",\"type\":\"CDSView\"}},\"id\":\"404513db-de0f-4ed0-816d-baafeb98d22d\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"grid_line_color\":{\"value\":null},\"minor_grid_line_color\":{\"value\":\"#aaaaaa\"},\"minor_grid_line_dash\":[2,4],\"plot\":{\"id\":\"0aca651c-7e06-486a-a56a-85397408c832\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"71bd440f-aa59-46f7-8f9f-dfaa8dc0e084\",\"type\":\"BasicTicker\"}},\"id\":\"a3b7876c-08e5-471b-a304-55fa90448162\",\"type\":\"Grid\"}],\"root_ids\":[\"0aca651c-7e06-486a-a56a-85397408c832\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.9\"}};\n",
       "    var render_items = [{\"docid\":\"590bfea0-4bf0-4a1f-95d7-41b8011b90f9\",\"elementid\":\"2f1119ed-dedc-4cac-9c93-77a831002589\",\"modelid\":\"0aca651c-7e06-486a-a56a-85397408c832\",\"notebook_comms_target\":\"a31ae18d-9af7-4435-90ef-65e539cf1fc7\"}];\n",
       "\n",
       "    root.Bokeh.embed.embed_items(docs_json, render_items);\n",
       "  }\n",
       "\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to embed document because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "0aca651c-7e06-486a-a56a-85397408c832"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot.start(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
